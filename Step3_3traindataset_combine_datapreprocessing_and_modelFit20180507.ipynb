{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这里使用pycharm 多核运算好的数据，\n",
    "    分三个训练集，一个给 特征 1,2,4用，一个专门给 3用，一个专门给 5用\n",
    "     并且使用 10% 的阈值，即 3850 和 删掉训练标签集中 abnormal 的\n",
    "     整个程序耗时 3.5mins 只有两个输入csv，设定相关阈值后 直接输出分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 子函数，用于删除从 csv 中读入文件的第一行\n",
    "def func_delete_Unnamed0(df_from_csv):\n",
    "    df_delete_Unnamed0 =df_from_csv.drop(['Unnamed: 0'],axis=1)\n",
    "    return df_delete_Unnamed0\n",
    "\n",
    "# 函数功能：第一次筛选，筛选特征值，只保留对应一个特征，其数据值超过阈值的特征\n",
    "# 输入：df_all_feature ：待处理的数据集，包含较多特征，需要减少特征\n",
    "#       num_threshold_feature ：特征值对应的数据个数的阈值\n",
    "def select_feature_via_threshold(df_all_feature,num_threshold_feature):\n",
    "    num_rows = df_all_feature.shape[0]\n",
    "    num_columns =  df_all_feature.shape[1]\n",
    "    # 输入的数据集的特征名称列表\n",
    "    list_feature_names = df_all_feature.columns.tolist()\n",
    "    # 特征对应数据值超过阈值的特征名称 组成的列表\n",
    "    list_feature_names_after_threshold = []\n",
    "    for i in range(num_columns):\n",
    "        if df_all_feature.iloc[:,i].count() >= num_threshold_feature:\n",
    "            list_feature_names_after_threshold.append(list_feature_names[i])\n",
    "   \n",
    "    df_selected_via_feature_threshold = df_all_feature[list_feature_names_after_threshold]\n",
    "    return df_selected_via_feature_threshold  \n",
    "\n",
    "# 38199 中删除 49个不良数据\n",
    "# 清洗数据，看是否有重复数据\n",
    "# 经过验证，没有重复数据，TODO：func_delete_repeat_cows_df 添加一个返回值，返回由重复元素组成的df\n",
    "# 子函数，删除列表中重复元素，还是原始顺序\n",
    "# 删除 dataframe 有简单方法 df.drop(df.index[[1,3]])\n",
    "def func_delete_repeat_element_list(list_with_repeat):\n",
    "    list_without_repeat = list(set(list_with_repeat))\n",
    "    list_without_repeat.sort(key=list_with_repeat.index)\n",
    "    return list_without_repeat\n",
    "\n",
    "def func_delete_repeat_cows_df(df,str_id_name):\n",
    "    list_id_names = df[str_id_name].tolist()\n",
    "    list_id_names_without_repeat = func_delete_repeat_element_list(list_id_names)\n",
    "    df_without_repeat = df[df[str_id_name].isin(list_id_names_without_repeat)]\n",
    "    return df_without_repeat\n",
    "\n",
    "# 筛选出不良数据\n",
    "# 子函数，删除列表中重复元素，还是原始顺序\n",
    "def func_delete_repeat_element_list(list_with_repeat):\n",
    "    list_without_repeat = list(set(list_with_repeat))\n",
    "    list_without_repeat.sort(key=list_with_repeat.index)\n",
    "    return list_without_repeat\n",
    "\n",
    "def func_judge_isnot_change_str(check_str):\n",
    "    try:\n",
    "        float(check_str)\n",
    "        return False\n",
    "    except ValueError:\n",
    "        return True\n",
    "    \n",
    "# 行的循环改为通过 index 的列表循环\n",
    "# 为了精准，返回值是 id号组成的列表\n",
    "def func_select_sample_cannot_change_str(df_under):\n",
    "    list_ID_cannot_change_str = []\n",
    "    list_index_cannot_change_str = []\n",
    "    list_index = df_under.index.tolist()\n",
    "    for i in list_index:\n",
    "       # 这里'vid' 特征是 str类型，但是要保存'vid'特征，'vid'特征是第0列，所以要从1开始循环\n",
    "        for j in range(1,df_under.shape[1]):\n",
    "            if func_judge_isnot_change_str( df_under.loc[i].values[j]) == True:\n",
    "                list_index_cannot_change_str.append(i)\n",
    "            \n",
    "    list_index_cannot_change_str_without_repeat = func_delete_repeat_element_list(list_index_cannot_change_str)\n",
    "    df_cannot_change_str = df_under.loc[list_index_cannot_change_str_without_repeat]\n",
    "    return df_cannot_change_str\n",
    "\n",
    "#删除 标签训练集中的不良数据\n",
    "def func_delete_df(df_under_deleted,df_deleter,str_ID_name):\n",
    "    list_under_deleted = df_under_deleted[str_ID_name].tolist()\n",
    "    list_deleter = df_deleter[str_ID_name].tolist()\n",
    "    list_difference =  list(set(list_under_deleted) ^ set(list_deleter))\n",
    "    df_result = df_under_deleted[df_under_deleted[str_ID_name].isin(list_difference)]\n",
    "    return df_result\n",
    "\n",
    "# 功能：从全体样本中筛选出部分样本\n",
    "# str_feature_type：用于筛选的特征值\n",
    "def select_sample_has_label(df_all_sample,df_part_sample,str_feature_type):\n",
    "    # 获取标签训练集的 ID list  即 vid 的 list\n",
    "    list_vid_train_label =df_part_sample[str_feature_type].tolist()\n",
    "    # 根据ID号，筛选出38199个样本，再组成一个新的 dataframe\n",
    "    df_selected_via_vid = df_all_sample.loc[df_all_sample[str_feature_type].isin(list_vid_train_label)]\n",
    "    # 之前的 index 还是断断续续的，扔掉之前的，重新从0开始排序\n",
    "    df_selected_via_vid_index_resetted = df_selected_via_vid.reset_index(drop=True)\n",
    "    return df_selected_via_vid_index_resetted\n",
    "\n",
    "# 训练特征集重新排序\n",
    "def func_sort_df(df_under_sorted,df_model,str_sort_key):\n",
    "    list_sorter=  df_model[str_sort_key].tolist()\n",
    "    dict_sorterIndex = dict(zip(list_sorter,range(len(list_sorter))))\n",
    "    str_sort_key_rank = str_sort_key + '_rank'\n",
    "    df_under_sorted[str_sort_key_rank] = df_under_sorted[str_sort_key].map(dict_sorterIndex)\n",
    "    df_under_sorted.sort_values([str_sort_key_rank], \\\n",
    "        ascending = [True ], inplace = True)\n",
    "    df_under_sorted.drop(str_sort_key_rank, 1, inplace = True)\n",
    "    #df_sorted = df_under_sorted[df_under_sorted[str_sort_key].isin(list_model_sort_key)]\n",
    "    return df_under_sorted\n",
    "\n",
    "# 删除 df总对应vid的list的样本\n",
    "def func_delete_df_by_list(df_under_deleted,list_deleter,str_ID_name):\n",
    "    list_under_deleted = df_under_deleted[str_ID_name].tolist()\n",
    "    list_difference =  list(set(list_under_deleted) ^ set(list_deleter))\n",
    "    df_result = df_under_deleted[df_under_deleted[str_ID_name].isin(list_difference)]\n",
    "    return df_result\n",
    "# 转 flaot 类型子函数\n",
    "def change_not_float_to_nan(check_str):\n",
    "    try:\n",
    "        float(check_str)\n",
    "        str_c = float(check_str)\n",
    "        return str_c\n",
    "    except ValueError:\n",
    "        check_str = np.nan\n",
    "        return check_str\n",
    "\n",
    "def func_str_to_float_df(df_str):\n",
    "    df_str=df_str.reset_index(drop=True)\n",
    "    df_float = df_str\n",
    "    for i in range(df_str.shape[0]):\n",
    "        # 这里'vid' 特征是 str类型，但是要保存'vid'特征，'vid'特征是第0列，所以要从1开始循环\n",
    "        for j in range(1,df_str.shape[1]):\n",
    "            df_float.iat[i, j] = change_not_float_to_nan(df_str.loc[i].values[j])\n",
    "    return df_float \n",
    "    \n",
    "# 筛选范围异常值的子函数，用于判断标签训练集中 如血压值是否在合理范围内\n",
    "# 输出4个list\n",
    "def func_select_abnormal_values(df_label,\n",
    "                                num_low_threshold_abnormal,\n",
    "                                num_high_threshold_abnormal,\n",
    "                                num_squence_label,\n",
    "                                num_squence_ID):\n",
    "    list_index = df_label.index.tolist()\n",
    "    \n",
    "    list_low_value_abnormal = []\n",
    "    list_high_value_abnormal = []\n",
    "    list_low_vid_abnormal = []\n",
    "    list_high_vid_abnormal = []\n",
    "    \n",
    "    for i in list_index:\n",
    "        #print('type',type(df_label.loc[i].values[num_squence_label]))\n",
    "        if df_label.loc[i].values[num_squence_label] < num_low_threshold_abnormal:\n",
    "            list_low_value_abnormal.append(df_label.loc[i].values[num_squence_label])\n",
    "            list_low_vid_abnormal.append(df_label.loc[i].values[num_squence_ID])\n",
    "    \n",
    "    for i in list_index:\n",
    "        if df_label.loc[i].values[num_squence_label] > num_high_threshold_abnormal:\n",
    "            list_high_value_abnormal.append(df_label.loc[i].values[num_squence_label])\n",
    "            list_high_vid_abnormal.append(df_label.loc[i].values[num_squence_ID])\n",
    "    \n",
    "    return list_low_value_abnormal,\\\n",
    "            list_high_value_abnormal,\\\n",
    "            list_low_vid_abnormal,\\\n",
    "            list_high_vid_abnormal\n",
    "            \n",
    "# 列表合并子函数\n",
    "def func_combine_list(list_a,list_b):\n",
    "    list_result =list_a + list_b\n",
    "    return list_result\n",
    "\n",
    "# 判断舒张压 是否 小于 收缩压 子函数\n",
    "def func_select_abnormal_relationship_two_labels(df_label,\n",
    "                                                num_squence_label_A,\n",
    "                                                num_squence_label_B,\n",
    "                                                 num_squence_ID):\n",
    "    list_index = df_label.index.tolist()\n",
    "    \n",
    "    list_value_abnormal_relationship_pair = []\n",
    "    list_vid_abnormal_relationship = []\n",
    "    \n",
    "    for i in list_index:\n",
    "        if df_label.loc[i].values[num_squence_label_A] <= df_label.loc[i].values[num_squence_label_B]:\n",
    "            list_value_abnormal_relationship_pair.append(df_label.loc[i].values[num_squence_label_A])\n",
    "            list_value_abnormal_relationship_pair.append(df_label.loc[i].values[num_squence_label_B])\n",
    "            list_value_abnormal_relationship_pair.append(',')\n",
    "            list_vid_abnormal_relationship.append(df_label.loc[i].values[num_squence_ID])\n",
    "    return  list_value_abnormal_relationship_pair,\\\n",
    "            list_vid_abnormal_relationship\n",
    "\n",
    "# 查找并处理标签训练集中异常值\n",
    "def func_delete_abnormal_value(df_under):\n",
    "    # 查找 收缩压中的异常值\n",
    "    list_low_SBP_abnormal,list_high_SBP_abnormal,list_vid_low_SBP_abnormal,list_vid_high_SBP_abnormal =  func_select_abnormal_values(df_label = df_under,\n",
    "                                                                                            num_low_threshold_abnormal = 50,\n",
    "                                                                                            num_high_threshold_abnormal = 300,\n",
    "                                                                                            num_squence_label = 1,\n",
    "                                                                                            num_squence_ID = 0)\n",
    "    # 合并2种异常值vid列表\n",
    "    list_vid_SBP_abnormal = func_combine_list(list_vid_low_SBP_abnormal,list_vid_high_SBP_abnormal)  \n",
    "    # 查找舒张压（DBP）异常值\n",
    "    list_low_DBP_abnormal,list_high_DBP_abnormal,list_vid_low_DBP_abnormal,list_vid_high_DBP_abnormal =  func_select_abnormal_values(df_label =df_under,\n",
    "                                                                                            num_low_threshold_abnormal = 30,\n",
    "                                                                                            num_high_threshold_abnormal = 200,\n",
    "                                                                                            num_squence_label = 2,\n",
    "                                                                                            num_squence_ID = 0)\n",
    "    list_vid_DBP_abnormal = func_combine_list(list_vid_low_DBP_abnormal,list_vid_high_DBP_abnormal)  \n",
    "    # 判断收缩压与舒张压关系异常的样本\n",
    "    list_value_abnormal_SBP_and_DBP ,  list_vid_abnormal_SBP_and_DBP = func_select_abnormal_relationship_two_labels(df_label = df_under,\n",
    "                                                                                                               num_squence_label_A = 1,\n",
    "                                                                                                               num_squence_label_B = 2,\n",
    "                                                                                                               num_squence_ID = 0)\n",
    "    # 查看血清甘油三脂（TG）的 异常值\n",
    "    # 都属于正常值\n",
    "    list_low_TG_abnormal,list_high_TG_abnormal,list_vid_low_TG_abnormal,list_vid_high_TG_abnormal =  func_select_abnormal_values(df_label = df_under,\n",
    "                                                                                            num_low_threshold_abnormal = 0.1,\n",
    "                                                                                            #num_high_threshold_abnormal = 16.5,\n",
    "                                                                                            num_high_threshold_abnormal = 5,\n",
    "                                                                                            num_squence_label = 3,\n",
    "                                                                                            num_squence_ID = 0)\n",
    "    list_vid_TG_abnormal = func_combine_list(list_vid_low_TG_abnormal,list_vid_high_TG_abnormal)  \n",
    "    # 查看血清高密度脂蛋白（HDL）的 异常值\n",
    "    list_low_HDL_abnormal,list_high_HDL_abnormal,list_vid_low_HDL_abnormal,list_vid_high_HDL_abnormal =  func_select_abnormal_values(df_label = df_under,\n",
    "                                                                                            num_low_threshold_abnormal = 0.5,\n",
    "                                                                                            num_high_threshold_abnormal = 5,\n",
    "                                                                                            num_squence_label = 4,\n",
    "                                                                                            num_squence_ID = 0)\n",
    "    list_vid_HDL_abnormal = func_combine_list(list_vid_low_HDL_abnormal,list_vid_high_HDL_abnormal)  \n",
    "    # 查看血清低密度脂蛋白（LDL）的 异常值\n",
    "    # 结果中竟然有类负数，这些数据要删除\n",
    "    list_low_LDL_abnormal,list_high_LDL_abnormal,list_vid_low_LDL_abnormal,list_vid_high_LDL_abnormal =  func_select_abnormal_values(df_label = df_under,\n",
    "                                                                                            #num_low_threshold_abnormal = 0,\n",
    "                                                                                            num_low_threshold_abnormal = 0,\n",
    "                                                                                            #num_high_threshold_abnormal = 12,\n",
    "                                                                                            num_high_threshold_abnormal = 12,\n",
    "                                                                                            num_squence_label = 5,\n",
    "                                                                                            num_squence_ID = 0)\n",
    "    list_vid_LDL_abnormal = func_combine_list(list_vid_low_LDL_abnormal,list_vid_high_LDL_abnormal) \n",
    "    # 总的 异常标签值 对应的vid列表\n",
    "    list_vid_three_abnormal = list_vid_SBP_abnormal +\\\n",
    "                                list_vid_DBP_abnormal +\\\n",
    "                                list_vid_HDL_abnormal +\\\n",
    "                                list_vid_abnormal_SBP_and_DBP\n",
    "    # 去除重复数据\n",
    "    list_vid_three_abnormal = func_delete_repeat_element_list(list_vid_three_abnormal)\n",
    "    list_vid_TG_abnormal = func_delete_repeat_element_list(list_vid_TG_abnormal)\n",
    "    list_vid_LDL_abnormal = func_delete_repeat_element_list(list_vid_LDL_abnormal)\n",
    "    return list_vid_three_abnormal,list_vid_TG_abnormal, list_vid_LDL_abnormal\n",
    "            \n",
    "# 通过写入再读取的方式 讲str类型转换为float类型    \n",
    "def func_df_str_to_float_by_read_csv(df_str):\n",
    "    df_str.to_csv('temp_str_to_float.csv',index = False)\n",
    "    df_float = pd.read_csv('temp_str_to_float.csv')\n",
    "    return df_float\n",
    "   \n",
    "\n",
    "def print_df_info(df):\n",
    "    print(\"\\n\", \"\\n\", df.shape) \n",
    "    print(\"\\n\",\"\\n\",df.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " dataset_train_label_cannot_change_str_deleted.shape:  \n",
      " (38150, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 读取 pycharm 多核运算 根据 10%为阈值筛选出的 数据 [38199 * 286]\n",
    "    dataset_train_feature_all_float_read = pd.read_csv('dataset_train_feature_all_float_ten_per.csv')\n",
    "    # 导入标签数据\n",
    "    dataset_train_label= pd.read_csv(\"meinian_round1_train_20180408.csv\", encoding=\"gb2312\")  \n",
    "    # 删除第一列的index\n",
    "    dataset_train_feature_all_float = func_delete_Unnamed0(dataset_train_feature_all_float_read)\n",
    "    # 第二次筛选\n",
    "    num_threshold_feature = 3850\n",
    "    dataset_train_feature_selected_by_threshold_second = select_feature_via_threshold(dataset_train_feature_all_float,num_threshold_feature)\n",
    "    # 清洗数据，看是否有重复数据\n",
    "    dataset_train_label = func_delete_repeat_cows_df(dataset_train_label,'vid')\n",
    "    # 筛选出不良数据\n",
    "    dataset_train_label_cannot_change_str = func_select_sample_cannot_change_str(dataset_train_label)\n",
    "    #删除 标签训练集中的不良数据\n",
    "    # TODO 时间有限，这里应该 把'>6.22' 这里的数据提取出 6.22 的，这里不做处理，直接删除这样的数据\n",
    "    dataset_train_label_cannot_change_str_deleted = func_delete_df(dataset_train_label,\n",
    "                                                               dataset_train_label_cannot_change_str,\n",
    "                                                              'vid')\n",
    "    ## 删除特征训练集中 对应标签训练集中的不良数据\n",
    "    dataset_train_feature_cannot_change_str_deleted = func_delete_df(dataset_train_feature_selected_by_threshold_second,\n",
    "                                                                dataset_train_label_cannot_change_str,\n",
    "                                                                'vid')\n",
    "   \n",
    "    # 通过写入再读取的方式 讲str类型转换为float类型\n",
    "    dataset_train_label_cannot_change_str_deleted = func_df_str_to_float_by_read_csv(dataset_train_label_cannot_change_str_deleted )\n",
    "\n",
    "    print (\"\\n\", \"dataset_train_label_cannot_change_str_deleted.shape: \",\"\\n\",\n",
    "           dataset_train_label_cannot_change_str_deleted.shape)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  dataset_train_feature_three_sorted_by_dataset_label.shape:  \n",
      " (38144, 136)\n",
      "\n",
      "  dataset_train_label_three_abnormal_deleted.shape:  \n",
      " (38144, 6)\n",
      "\n",
      "  dataset_train_feature_TG_sorted_by_dataset_label.shape:  \n",
      " (37353, 136)\n",
      "\n",
      "  dataset_train_label_TG_abnormal_deleted.shape:  \n",
      " (37353, 6)\n",
      "\n",
      "  dataset_train_feature_LDL_sorted_by_dataset_label.shape:  \n",
      " (38147, 136)\n",
      "\n",
      "  dataset_train_label_LDL_abnormal_deleted.shape:  \n",
      " (38147, 6)\n"
     ]
    }
   ],
   "source": [
    "# 计算所有 标签训练集中 abnormal 数据对应 vid 的list\n",
    "    #list_vid_five_abnormal = func_delete_abnormal_value(dataset_train_label_cannot_change_str_deleted)\n",
    "    # 再次删除 标签训练集中 abnormal 数据\n",
    "   \n",
    "list_vid_three_abnormal,list_vid_TG_abnormal,list_vid_LDL_abnormal = func_delete_abnormal_value(dataset_train_label_cannot_change_str_deleted)\n",
    "    # 再次删除 标签训练集中 abnormal 数据\n",
    "dataset_train_label_three_abnormal_deleted =  func_delete_df_by_list(dataset_train_label_cannot_change_str_deleted,\n",
    "                                                                         list_vid_three_abnormal,\n",
    "                                                                         'vid')\n",
    "dataset_train_label_TG_abnormal_deleted =  func_delete_df_by_list(dataset_train_label_cannot_change_str_deleted,\n",
    "                                                                      list_vid_TG_abnormal,\n",
    "                                                                      'vid')\n",
    "dataset_train_label_LDL_abnormal_deleted =  func_delete_df_by_list(dataset_train_label_cannot_change_str_deleted,\n",
    "                                                                       list_vid_LDL_abnormal,\n",
    "                                                                       'vid')\n",
    "    ## 第二次 删除，删除 训练特征集中 对应 训练标签集中的 abnormal 数据\n",
    "dataset_train_feature_three_abnormal_deleted = select_sample_has_label(dataset_train_feature_cannot_change_str_deleted,\n",
    "                                                      dataset_train_label_three_abnormal_deleted,\n",
    "                                                       'vid')\n",
    "dataset_train_feature_TG_abnormal_deleted = select_sample_has_label(dataset_train_feature_cannot_change_str_deleted,\n",
    "                                                      dataset_train_label_TG_abnormal_deleted,\n",
    "                                                       'vid')\n",
    "dataset_train_feature_LDL_abnormal_deleted = select_sample_has_label(dataset_train_feature_cannot_change_str_deleted,\n",
    "                                                      dataset_train_label_LDL_abnormal_deleted,\n",
    "                                                       'vid')\n",
    "    # 训练特征集重新排序\n",
    "dataset_train_feature_three_sorted_by_dataset_label = func_sort_df(dataset_train_feature_three_abnormal_deleted,\n",
    "                                                             dataset_train_label_three_abnormal_deleted,\n",
    "                                                             'vid')\n",
    "dataset_train_feature_TG_sorted_by_dataset_label = func_sort_df(dataset_train_feature_TG_abnormal_deleted,\n",
    "                                                             dataset_train_label_TG_abnormal_deleted,\n",
    "                                                             'vid')\n",
    "dataset_train_feature_LDL_sorted_by_dataset_label = func_sort_df(dataset_train_feature_LDL_abnormal_deleted,\n",
    "                                                             dataset_train_label_LDL_abnormal_deleted,\n",
    "                                                             'vid')\n",
    "dataset_train_feature_three_sorted_by_dataset_label.to_csv('dataset_train_feature_three_20180507.csv',index = False)\n",
    "dataset_train_feature_TG_sorted_by_dataset_label.to_csv('dataset_train_feature_TG_20180507.csv',index = False)\n",
    "dataset_train_feature_LDL_sorted_by_dataset_label.to_csv('dataset_train_feature_LDL_20180507.csv',index = False)\n",
    "\n",
    "dataset_train_label_three_abnormal_deleted.to_csv('dataset_train_label_three_20180507.csv',index = False)\n",
    "dataset_train_label_TG_abnormal_deleted.to_csv('dataset_train_label_TG_20180507.csv',index = False)\n",
    "dataset_train_label_LDL_abnormal_deleted.to_csv('dataset_train_label_LDL_20180507.csv',index = False)\n",
    "\n",
    "\n",
    "print (\"\\n\", \" dataset_train_feature_three_sorted_by_dataset_label.shape: \",\"\\n\",\n",
    "            dataset_train_feature_three_sorted_by_dataset_label.shape)\n",
    "print (\"\\n\", \" dataset_train_label_three_abnormal_deleted.shape: \",\"\\n\",\n",
    "            dataset_train_label_three_abnormal_deleted.shape)\n",
    "    \n",
    "print (\"\\n\", \" dataset_train_feature_TG_sorted_by_dataset_label.shape: \",\"\\n\",\n",
    "            dataset_train_feature_TG_sorted_by_dataset_label.shape)\n",
    "print (\"\\n\", \" dataset_train_label_TG_abnormal_deleted.shape: \",\"\\n\",\n",
    "            dataset_train_label_TG_abnormal_deleted.shape)\n",
    "    \n",
    "print (\"\\n\", \" dataset_train_feature_LDL_sorted_by_dataset_label.shape: \",\"\\n\",\n",
    "            dataset_train_feature_LDL_sorted_by_dataset_label.shape)\n",
    "print (\"\\n\", \" dataset_train_label_LDL_abnormal_deleted.shape: \",\"\\n\",\n",
    "            dataset_train_label_LDL_abnormal_deleted.shape)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " score_1:  \n",
      " 0.016163520030159778\n",
      "\n",
      " score_2:  \n",
      " 0.019717984561833612\n",
      "\n",
      " score_3:  \n",
      " 0.059463257350289796\n",
      "\n",
      " score_4:  \n",
      " 0.013740588374619958\n",
      "\n",
      " score_5:  \n",
      " 0.03755522946777588\n",
      "\n",
      " score_mean:  \n",
      " 0.029328115956935807\n"
     ]
    }
   ],
   "source": [
    "# 预测结果和计算得分\n",
    "def func_predict_and_score_XGBRegressor(df_X,df_Y):\n",
    "    X = df_X.iloc[:,1:]\n",
    "    array_X = np.array(X)\n",
    "    array_Y = np.array(df_Y)\n",
    "    seed=  7\n",
    "    test_size = 0.33\n",
    "    #test_size = 0.2\n",
    "    X_train, X_test, y_train, y_test = train_test_split(array_X,\n",
    "                                                        array_Y, \n",
    "                                                        test_size=test_size,\n",
    "                                                        random_state=seed)\n",
    "    model = XGBRegressor()\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "   \n",
    "    num_people = len(y_pred)\n",
    "    sum_score = 0\n",
    "    score = 0\n",
    "    for j in range(len(y_pred)):\n",
    "        sum_score = sum_score + (math.log(y_pred[j]+1) - math.log(y_test[j]+1)) ** 2\n",
    "    score = sum_score / num_people\n",
    "    list_ypred_and_score = []\n",
    "    list_ypred_and_score.append(y_pred)\n",
    "    list_ypred_and_score.append(score)\n",
    "    #list_ypred_and_score[0] = y_pred\n",
    "    #list_ypred_and_score[1] = score\n",
    "    #print (\"\\n\", \"y_pred: \",\"\\n\",y_pred)\n",
    "    return list_ypred_and_score \n",
    "# 训练模型，计算得分\n",
    "    # 预处理好的训练特征集\n",
    "dataset_train_feature_preprocessed_Three = dataset_train_feature_three_sorted_by_dataset_label\n",
    "dataset_train_feature_preprocessed_TG = dataset_train_feature_TG_sorted_by_dataset_label\n",
    "dataset_train_feature_preprocessed_LDL = dataset_train_feature_LDL_sorted_by_dataset_label\n",
    "    # 预处理好的训练标签集\n",
    "dataset_train_label_Three = dataset_train_label_three_abnormal_deleted\n",
    "dataset_train_label_TG = dataset_train_label_TG_abnormal_deleted\n",
    "dataset_train_label_LDL = dataset_train_label_LDL_abnormal_deleted\n",
    "\n",
    "#X = dataset_train_feature_preprocessed.iloc[:,1:]\n",
    "X_three = dataset_train_feature_preprocessed_Three.iloc[:,1:]\n",
    "X_TG = dataset_train_feature_preprocessed_TG.iloc[:,1:]\n",
    "X_LDL = dataset_train_feature_preprocessed_LDL.iloc[:,1:]\n",
    "\n",
    "Y_1 = dataset_train_label_Three.iloc[:,1]\n",
    "Y_2 = dataset_train_label_Three.iloc[:,2]\n",
    "Y_4 = dataset_train_label_Three.iloc[:,4]\n",
    "\n",
    "Y_3 = dataset_train_label_TG.iloc[:,3]\n",
    "Y_5 = dataset_train_label_LDL.iloc[:,5]\n",
    "\n",
    "score_1 = func_predict_and_score_XGBRegressor(X_three,Y_1)[1]\n",
    "score_2 = func_predict_and_score_XGBRegressor(X_three,Y_2)[1]\n",
    "score_3 = func_predict_and_score_XGBRegressor(X_TG,Y_3)[1]\n",
    "score_4 = func_predict_and_score_XGBRegressor(X_three,Y_4)[1]\n",
    "score_5 = func_predict_and_score_XGBRegressor(X_LDL,Y_5)[1]\n",
    "\n",
    "# 计算得分子函数\n",
    "score_mean  = (score_1 + score_2 + score_3 + score_4 + score_5) / 5\n",
    "print (\"\\n\", \"score_1: \",\"\\n\",score_1)\n",
    "print (\"\\n\", \"score_2: \",\"\\n\",score_2)\n",
    "print (\"\\n\", \"score_3: \",\"\\n\",score_3)\n",
    "print (\"\\n\", \"score_4: \",\"\\n\",score_4)\n",
    "print (\"\\n\", \"score_5: \",\"\\n\",score_5)\n",
    "print (\"\\n\", \"score_mean: \",\"\\n\",score_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进入模型训练部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
